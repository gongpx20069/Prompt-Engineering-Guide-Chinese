# 杂项主题

在本节中，我们讨论了 Prompt 工程中其他杂项和未分类的主题。它包括相对较新的想法和方法，随着它们被更广泛地采纳，最终将被移动到主要指南中。本指南部分也有助于跟上最新的 Prompt 工程研究论文。

**请注意，本节正在大量开发中。**

主题：
- [Active Prompt](#active-prompt)
- [定向刺激 Prompting](#定向刺激-prompting)
- [ReAct](#react)
- [多模态 CoT Prompting](#多模态-prompting)
- [GraphPrompts](#graphprompts)
- ...

---

## Active-Prompt

链式思考（CoT）方法依赖于一组固定的人类注释示例。问题在于，这些示例可能不是不同任务最有效的例子。为了解决这个问题，[Diao 等人，(2023)](https://arxiv.org/pdf/2302.12246.pdf) 最近提出了一种新的 Prompting 方法，称为 Active-Prompt，以适应 LLMs 不同的特定于任务的示例 Prompts（带有人类设计的 CoT 推理注释）。

下图说明了这种方法。第一步是用或不用几个 CoT 示例查询 LLM。为一组训练问题生成 *k* 个可能的答案。基于 *k* 个答案计算不确定性指标（使用不一致性）。选择最不确定的问题由人类进行注释。然后使用新注释的示例来推断每个问题。

![](../img/active-prompt.png)

---
## 定向刺激 Prompting
[Li 等人，(2023)](https://arxiv.org/abs/2302.11520) 提出了一种新的 Prompting 技术，以更好地指导 LLM 生成所需的摘要。

训练一个可调策略 LM 来生成刺激/提示。看到更多使用 RL 来优化 LLMs。

下图显示了定向刺激 Prompting 与标准 Prompting 的比较。策略 LM 可以很小，并优化以生成引导黑盒冻结 LLM 的提示。

![](../img/dsp.jpeg)

完整示例即将推出！

---
## ReAct

[Yao 等人，2022](https://arxiv.org/abs/2210.03629) 引入了一个框架，在该框架中，LLMs 用于以交错的方式生成推理轨迹和特定于任务的行动。生成推理轨迹允许模型引导、跟踪和更新行动计划，甚至处理异常。行动步骤允许与外部资源（如知识库或环境）进行交互并收集信息。

ReAct 框架可以允许 LLMs 与外部工具交互以检索额外信息，从而导致更可靠和事实的响应。

![](../img/react.png)

完整示例即将推出！

---
## 多模态 CoT Prompting

[Zhang 等人 (2023)](https://arxiv.org/abs/2302.00923) 最近提出了一种多模态链式思考 Prompting 方法。传统的 CoT 专注于语言模态。相比之下，多模态 CoT 将文本和视觉结合到一个两阶段框架中。第一步涉及基于多模态信息的理由生成。其次是第二阶段，答案推理，利用信息丰富的生成理由。

多模态 CoT 模型（1B）在 ScienceQA 基准测试上胜过 GPT-3.5。

![](../img/multimodal-cot.png)

进一步阅读：
- [语言并非你所需要的一切：将感知与语言模型对齐](https://arxiv.org/abs/2302.14045)（2023年2月）

---
## GraphPrompts

[Liu 等人，2023](https://arxiv.org/abs/2302.08043) 引入了 GraphPrompt，这是一个新的图提示框架，用于改善下游任务的性能。

更多内容即将推出！

---
[上一节 (可靠性)](./prompts-reliability.md)
