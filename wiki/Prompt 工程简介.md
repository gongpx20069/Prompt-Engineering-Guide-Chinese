# Prompt 工程简介  
  
Prompt 工程是一个相对较新的学科，它专注于开发和优化 Prompt，以高效地使用语言模型（LMs）处理各种应用和研究主题。掌握 Prompt 工程技能有助于更好地理解大型语言模型（LLMs）的能力和局限性。研究人员利用 Prompt 工程提升 LLMs 在诸如问答和算术推理等常见和复杂任务上的能力。开发者使用 Prompt 工程设计健壮且有效的 Prompt 技术，以便与 LLMs 和其他工具进行交互。  
  
本指南涵盖了标准 Prompt 的基础知识，以提供如何使用 Prompt 与大型语言模型（LLMs）进行交互和指导的基本概念。  
  
所有示例均在 `text-davinci-003`（使用 OpenAI 的 playground）上测试，除非另有说明。它使用默认配置，例如 `temperature=0.7` 和 `top-p=1`。  
  
主题：  
- [基础 Prompts](#基础-prompts)  
- [关于 LLM 设置的说明](#关于-llm-设置的说明)  
- [标准 Prompts](#标准-prompts)  
- [Prompt 元素](#prompt-元素)  
- [设计 Prompts 的通用技巧](#设计-prompts-的通用技巧)  
  
---  
  
## 基础 Prompts  
  
你已经可以通过 Prompts 实现很多事情，但结果的质量取决于你提供的信息量。一个 Prompt 可以包含诸如向模型传递的 `instruction` 或 `question` 信息，并包括其他细节，如 `inputs` 或 `examples`。  
  
这里有一个简单 Prompt 的基本示例：  
  
*Prompt*  
```  
天空是  
```  
  
*Output:*  
```  
蓝色的  
  
天空在晴朗的日子里是蓝色的。在多云的日子里，天空可能是灰色或白色的。  
```  
  
如你所见，语言模型输出了一系列在上下文 `"天空是"` 中有意义的字符串。输出可能是意外的，或者与我们想要完成的任务相去甚远。  
  
这个基础示例还突出了提供更多上下文或指令的必要性，以明确我们想要实现的具体目标。  
  
让我们尝试改进一下：  
  
*Prompt:*  
```  
完成句子：  
  
天空是  
```  
  
*Output:*  
  
```  
蔚蓝色的。 
```  
  
这样是否更好？嗯，我们告诉模型完成句子，所以结果看起来好多了，因为它完全按照我们告诉它的做法来做（"完成句子"）。这种设计最佳 Prompt 来指导模型执行任务的方法，被称为 **Prompt 工程**。  
  
上面的示例是当今 LLMs 可能性的基本描绘。今天的 LLMs 可以执行各种高级任务，从文本摘要到数学推理再到代码生成。  
  
---  
## 关于 LLM 设置的说明  
  
当使用 Prompts 时，你将通过 API 或直接与 LLM 进行交云。你可以配置一些参数，以获得你的 Prompts 的不同结果。  
  
**Temperature** - 简而言之，温度越低，结果越确定性，意味着总是选择最有可能的下一个 token。提高温度可能会导致更多随机性，鼓励更多样化或创造性的输出。我们实际上是在增加其他可能 token 的权重。在应用方面，我们可能希望在类似基于事实的 QA 中使用较低的温度，以鼓励更事实和简洁的回应。对于诗歌创作或其他创造性任务，可能会有益于提高温度。  
  
**Top_p** - 同样地，通过称为核心抽样的温度采样技术 top_p，你可以控制模型生成响应的确定性。如果你在寻找准确和事实上的答案，请保持这个值低。如果你在寻找更多样化的响应，请将其增加到更高的值。  
  
通常的建议是改变其中一个，而不是两个。  
  
在开始一些基本示例之前，请记住，你的结果可能会因为你使用的 LLM 版本而有所不同。  
  
---  
## 标准 Prompts  
  
我们在上面尝试了一个非常简单的 Prompt。标准 Prompt 有以下格式：  
  
```  
<Question>?  
```  
   
这可以格式化为 QA 格式，这在许多 QA 数据集中是标准的，如下所示：  
  
```  
Q: <Question>?  
A:   
```  
  
考虑到上述标准格式，一种流行且有效的 Prompt 技巧被称为 few-shot prompting，我们提供示例。Few-shot Prompts 可以格式化如下：  
  
```  
<Question>?  
<Answer>  
  
<Question>?  
<Answer>  
  
<Question>?  
<Answer>  
  
<Question>?  
  
```  
  
  
你可以猜到它的 QA 格式版本会是这样的：  
  
```  
Q: <Question>?  
A: <Answer>  
  
Q: <Question>?  
A: <Answer>  
  
Q: <Question>?  
A: <Answer>  
  
Q: <Question>?  
A:  
```  
  
请记住，不需要使用 QA 格式。格式取决于手头的任务。例如，你可以执行一个简单的分类任务，并给出示例来演示任务，如下所示：  
  
*Prompt:*  
```  
这太棒了！ // 正面  
这很糟糕！ // 负面  
哇，那部电影太酷了！ // 正面  
多么糟糕的节目！ //  
```  
  
*Output:*  
```  
负面  
```  
  
Few-shot Prompts 使得语境中的学习成为可能，即语言模型仅通过几个示例就能学习任务。在即将到来的指南中，我们将看到更多这方面的实践。  
  
---  
## Prompt 元素  
  
当我们覆盖越来越多可能通过 Prompt 工程实现的示例和应用时，你会注意到构成 Prompt 的某些元素。  
  
一个 Prompt 可以包含以下任何组件：  
  
**Instruction** - 你希望模型执行的特定任务或指令  
  
**Context** - 可以涉及外部信息或额外的上下文，可以引导模型提供更好的响应  
  
**Input Data** - 我们感兴趣找到响应的输入或问题  
  
**Output Indicator** - 指示输出的类型或格式。  
  
并非所有组件都需要用于 Prompt，格式取决于手头的任务。我们将在即将到来的指南中触及更具体的示例。  
  
---  
## 设计 Prompts 的通用技巧  
  
在设计你的 Prompts 时，请记住以下一些技巧：  
  
  
### 从简单开始  
当你开始设计 Prompts 时，应该记住这是一个需要大量实验才能获得最佳结果的迭代过程。使用像 OpenAI 或 Cohere 的简单 playground 是一个很好的起点。  
  
你可以从简单的 Prompts 开始，随着你寻求更好的结果，继续添加更多元素和上下文。出于这个原因，沿途对你的 Prompt 进行版本控制至关重要。当我们阅读指南时，你会看到许多示例，其中具体性、简单性和简洁性通常会带来更好的结果。  
  
当你有一个涉及许多不同子任务的大任务时，你可以尝试将任务分解成更简单的子任务，并在获得更好的结果时继续构建。这避免了在开始时就给 Prompt 设计过程增加太多复杂性。  
  
### 指令  
你可以通过使用命令来指导模型你想要实现的目标，如 "写作"、"分类"、"总结"、"翻译"、"排序" 等，为各种简单任务设计有效的 Prompts。  
  
请记住，你还需要进行大量实验才能看到哪些效果最好。尝试使用不同的指令、不同的关键词、上下文和数据，看看哪些对你的特定用例和任务最有效。通常，上下文越具体且与你试图执行的任务越相关，效果越好。我们将在即将到来的指南中讨论采样的重要性和添加更多上下文的重要性。  
  
其他人建议将指令放在 Prompt 的开头。他们还建议使用一些清晰的分隔符，如 "###"，来分隔指令和上下文。  
  
例如：  
  
*Prompt:*  
```  
### 指令 ###  
将下面的文本翻译成西班牙语：  
  
文本："hello!"  
```  
  
*Output:*  
```  
¡Hola!  
```  
  
### 具体性  
对于你希望模型执行的指令和任务要非常具体。Prompt 越描述性和详细，结果越好。这在你有期望的结果或你寻求的生成风格时尤其重要。没有特定的 token 或关键词能带来更好的结果。更重要的是有一个好的格式和描述性的 Prompt。在 Prompt 中提供示例非常有效，以获得特定格式的期望输出。  
  
在设计 Prompts 时，你还应该记住 Prompt 的长度，因为这方面有限制。考虑你应该多具体和详细是需要考虑的事情。太多不必要的细节不一定是好方法。细节应该是相关的，并有助于手头的任务。这是你需要进行大量实验的事情。我们鼓励大量的实验和迭代，以优化你的应用程序的 Prompts。  
  
例如，让我们尝试一个简单的 Prompt，从一段文本中提取特定信息。  
  
*Prompt:*  
```  
从以下文本中提取地名。  
  
期望格式：  
地点：<逗号分隔的地名列表>  
  
输入："尽管这些发展对研究人员来说是鼓舞人心的，但仍有许多是未知的。'我们经常在大脑和我们在外围看到的效果之间有一个黑匣子，'里斯本的无名中心的神经免疫学家 Henrique Veiga-Fernandes 说。'如果我们想在治疗上下文中使用它，我们需要理解机制。"  
```  
  
*Output:*  
```  
地点：无名中心，里斯本  
```  
  
输入文本取自 [自然杂志文章](https://www.nature.com/articles/d41586-023-00509-z)。  
  
### 避免不精确  
  
鉴于上述关于详细和改进格式的提示，很容易陷入想要过于聪明地处理 Prompts 并可能创建不精确描述的陷阱。通常更好的做法是具体和直接。这里的类比与有效沟通非常相似——越直接，信息传递越有效。  
  
例如，你可能对学习 Prompt 工程的概念感兴趣。你可能会尝试这样的东西：  
  
```  
解释 Prompt 工程的概念。保持解释简短，只有几句话，不要太描述性。  
```  
  
从上面的 Prompt 中不清楚要使用多少句子以及什么风格。你可能仍然会得到上述 Prompts 的良好响应，但更好的 Prompt 是非常具体、简洁和直接的。比如：  
  
```  
用 2-3 句话向一名高中生解释 Prompt 工程的概念。  
```  
  
### 做还是不做？  
设计 Prompts 时的另一个常见技巧是避免说不要做什么，而是说要做什么。这鼓励更具体性，并专注于导致模型良好响应的细节。  
  
这是一个电影推荐聊天机器人因为我写指令时关注了不要做什么而失败的例子。  
  
*Prompt:*  
```  
以下是向客户推荐电影的代理。不要询问兴趣。不要询问个人信息。  
  
客户：请根据我的兴趣推荐一部电影。  
代理：  
```  
  
*Output:*  
```  
当然，我可以根据你的兴趣推荐一部电影。你想看什么类型的电影？你喜欢动作片、喜剧片、爱情片还是其他？  
```  
  
这是一个更好的 Prompt：  
  
*Prompt:*  
```  
以下是向客户推荐电影的代理。代理负责从全球热门电影中推荐电影。它应该避免询问用户的偏好，并避免询问个人信息。如果代理没有电影推荐，应该回答“抱歉，今天找不到推荐的电影”。  
  
客户：请根据我的兴趣推荐一部电影。  
代理：  
```  
  
*Output:*  
```  
抱歉，我没有关于你兴趣的信息。不过，这里有一份全球热门电影的榜单：[电影列表]。希望你能找到你喜欢的东西！  
```  
  
上面的一些示例采用自 ["OpenAI API 提示工程最佳实践" 文章。](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)  
  
  
---  
[下一节 (基础 Prompt)](./基础&ensp;Prompt.md)